"""
Regression Analyzer - ê³ ê¸‰ íšŒê·€ë¶„ì„ ì „ìš© ëª¨ë“ˆ
OLS íšŒê·€ë¶„ì„, ì”ì°¨ë¶„ì„, Durbin-Watson í…ŒìŠ¤íŠ¸, Cook's Distance ë“±
"""

import logging
import warnings
from typing import Any, Dict, List, Optional

import numpy as np
from scipy import stats

warnings.filterwarnings("ignore")
logger = logging.getLogger(__name__)


class RegressionAnalyzer:
    def __init__(self) -> None:
        self.r2_threshold: float = 0.99
        self.outlier_threshold: float = 3.0
        self.confidence_level: float = 0.95

        print("ğŸ“ˆ Regression Analyzer ì´ˆê¸°í™” ì™„ë£Œ")

    def perform_comprehensive_regression(
        self,
        x_data: np.ndarray,
        y_data: np.ndarray,
        compound_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ì¢…í•©ì ì¸ íšŒê·€ë¶„ì„ ìˆ˜í–‰

        Args:
            x_data: ë…ë¦½ë³€ìˆ˜ (Log P)
            y_data: ì¢…ì†ë³€ìˆ˜ (RT)
            compound_names: í™”í•©ë¬¼ ì´ë¦„ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì¢…í•© íšŒê·€ë¶„ì„ ê²°ê³¼
        """

        if len(x_data) < 3:
            return self._minimal_regression_result(x_data, y_data)

        try:
            # 1. ê¸°ë³¸ OLS íšŒê·€ë¶„ì„
            basic_regression = self._perform_ols_regression(x_data, y_data)

            # 2. ì”ì°¨ ì§„ë‹¨
            residual_diagnostics = self._comprehensive_residual_analysis(
                basic_regression["residuals"], basic_regression["predicted_values"]
            )

            # 3. ì˜í–¥ë ¥ ì§„ë‹¨ (Cook's Distance, Leverage, DFFITS)
            influence_diagnostics = self._influence_diagnostics(
                x_data, y_data, basic_regression
            )

            # 4. ê³ ê¸‰ ì´ìƒì¹˜ íƒì§€
            outlier_analysis = self._advanced_outlier_detection(
                x_data, y_data, basic_regression, compound_names
            )

            # 5. ëª¨ë¸ ê°€ì • ê²€ì •
            assumption_tests = self._test_regression_assumptions(
                basic_regression["residuals"],
                basic_regression["predicted_values"],
                x_data,
            )

            # 6. ì˜ˆì¸¡ êµ¬ê°„ ê³„ì‚°
            prediction_intervals = self._calculate_prediction_intervals(
                x_data, y_data, basic_regression
            )

            # 7. ëª¨ë¸ í’ˆì§ˆ í‰ê°€
            model_quality = self._evaluate_model_quality(
                basic_regression, residual_diagnostics, assumption_tests
            )

            return {
                "basic_regression": basic_regression,
                "residual_diagnostics": residual_diagnostics,
                "influence_diagnostics": influence_diagnostics,
                "outlier_analysis": outlier_analysis,
                "assumption_tests": assumption_tests,
                "prediction_intervals": prediction_intervals,
                "model_quality": model_quality,
                "analysis_summary": self._generate_analysis_summary(
                    basic_regression, model_quality, outlier_analysis
                ),
            }

        except (ValueError, np.linalg.LinAlgError) as e:
            # Numerical errors in regression calculation
            logger.error(f"Regression numerical error: {e}")
            print(f"Regression numerical error: {str(e)}")
            return self._error_regression_result(f"Numerical error: {str(e)}")
        except Exception as e:
            # Unexpected errors
            logger.exception(f"Unexpected regression analysis error: {e}")
            print(f"Regression analysis error: {str(e)}")
            return self._error_regression_result(f"Unexpected error: {str(e)}")

    def _perform_ols_regression(
        self, x_data: np.ndarray, y_data: np.ndarray
    ) -> Dict[str, Any]:
        """ê¸°ë³¸ OLS íšŒê·€ë¶„ì„ ìˆ˜í–‰"""

        n = len(x_data)

        # ì„¤ê³„ í–‰ë ¬ ìƒì„± (ì ˆí¸ í¬í•¨)
        X = np.column_stack([np.ones(n), x_data])

        # OLS ì¶”ì •
        try:
            # ì •ê·œë°©ì •ì‹: Î² = (X'X)^(-1)X'y
            XTX_inv = np.linalg.inv(X.T @ X)
            beta = XTX_inv @ X.T @ y_data
        except np.linalg.LinAlgError:
            # íŠ¹ì´í–‰ë ¬ì¸ ê²½ìš° ìµœì†Œì œê³±ë²• ì‚¬ìš©
            beta, _, _, _ = np.linalg.lstsq(X, y_data, rcond=None)

        intercept, slope = beta[0], beta[1]

        # ì˜ˆì¸¡ê°’ ë° ì”ì°¨ ê³„ì‚°
        y_pred = X @ beta
        residuals = y_data - y_pred

        # í†µê³„ëŸ‰ ê³„ì‚°
        ss_total = np.sum((y_data - np.mean(y_data)) ** 2)
        ss_residual = np.sum(residuals**2)
        ss_regression = ss_total - ss_residual

        r2 = ss_regression / ss_total if ss_total > 0 else 0
        adjusted_r2 = (
            1 - (ss_residual / (n - 2)) / (ss_total / (n - 1)) if n > 2 else r2
        )

        # í‘œì¤€ì˜¤ì°¨ ê³„ì‚°
        mse = ss_residual / (n - 2) if n > 2 else 0
        se_slope = np.sqrt(mse * XTX_inv[1, 1]) if mse > 0 else 0
        se_intercept = np.sqrt(mse * XTX_inv[0, 0]) if mse > 0 else 0

        # t-í†µê³„ëŸ‰ ë° p-ê°’
        t_slope = slope / se_slope if se_slope > 0 else 0
        t_intercept = intercept / se_intercept if se_intercept > 0 else 0

        df = n - 2
        p_slope = 2 * (1 - stats.t.cdf(abs(t_slope), df)) if df > 0 else 0.5
        p_intercept = 2 * (1 - stats.t.cdf(abs(t_intercept), df)) if df > 0 else 0.5

        # F-í†µê³„ëŸ‰
        f_statistic = (
            (ss_regression / 1) / (ss_residual / df)
            if df > 0 and ss_residual > 0
            else 0
        )
        f_p_value = 1 - stats.f.cdf(f_statistic, 1, df) if df > 0 else 0.5

        return {
            "slope": float(slope),
            "intercept": float(intercept),
            "r2": float(r2),
            "adjusted_r2": float(adjusted_r2),
            "mse": float(mse),
            "rmse": float(np.sqrt(mse)),
            "se_slope": float(se_slope),
            "se_intercept": float(se_intercept),
            "t_slope": float(t_slope),
            "t_intercept": float(t_intercept),
            "p_slope": float(p_slope),
            "p_intercept": float(p_intercept),
            "f_statistic": float(f_statistic),
            "f_p_value": float(f_p_value),
            "predicted_values": y_pred.tolist(),
            "residuals": residuals.tolist(),
            "standardized_residuals": (residuals / np.std(residuals)).tolist()
            if np.std(residuals) > 0
            else residuals.tolist(),
            "n_observations": n,
            "degrees_freedom": df,
            "equation": f"RT = {slope:.4f} * Log_P + {intercept:.4f}",
        }

    def _comprehensive_residual_analysis(
        self, residuals: List[float], predicted_values: List[float]
    ) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ ì”ì°¨ ë¶„ì„"""

        residuals = np.array(residuals)
        predicted_values = np.array(predicted_values)

        # 1. Durbin-Watson ê²€ì • (ìê¸°ìƒê´€)
        dw_statistic = self._durbin_watson_test(residuals)

        # 2. Breusch-Pagan ê²€ì • (ë“±ë¶„ì‚°ì„±)
        bp_test = self._breusch_pagan_test(residuals, predicted_values)

        # 3. Shapiro-Wilk ê²€ì • (ì •ê·œì„±)
        shapiro_test = self._shapiro_wilk_test(residuals)

        # 4. ì”ì°¨ í†µê³„
        residual_stats = {
            "mean": float(np.mean(residuals)),
            "std": float(np.std(residuals)),
            "min": float(np.min(residuals)),
            "max": float(np.max(residuals)),
            "range": float(np.max(residuals) - np.min(residuals)),
            "skewness": float(stats.skew(residuals)),
            "kurtosis": float(stats.kurtosis(residuals)),
        }

        return {
            "durbin_watson": dw_statistic,
            "breusch_pagan": bp_test,
            "shapiro_wilk": shapiro_test,
            "residual_statistics": residual_stats,
            "autocorrelation_detected": dw_statistic["is_problematic"],
            "heteroscedasticity_detected": bp_test["is_heteroscedastic"],
            "non_normality_detected": not shapiro_test["is_normal"],
        }

    def _durbin_watson_test(self, residuals: np.ndarray) -> Dict[str, Any]:
        """Durbin-Watson ê²€ì • (1ì°¨ ìê¸°ìƒê´€ ê²€ì •)"""

        n = len(residuals)
        if n < 2:
            return {
                "statistic": 2.0,
                "interpretation": "ë°ì´í„° ë¶€ì¡±",
                "is_problematic": False,
            }

        # DW í†µê³„ëŸ‰ ê³„ì‚°
        diff_residuals = np.diff(residuals)
        dw_stat = np.sum(diff_residuals**2) / np.sum(residuals**2)

        # í•´ì„ (ê°„ëµí™”ëœ ê¸°ì¤€)
        if dw_stat < 1.5:
            interpretation = "ì–‘ì˜ ìê¸°ìƒê´€ ì˜ì‹¬"
            is_problematic = True
        elif dw_stat > 2.5:
            interpretation = "ìŒì˜ ìê¸°ìƒê´€ ì˜ì‹¬"
            is_problematic = True
        else:
            interpretation = "ìê¸°ìƒê´€ ì—†ìŒ"
            is_problematic = False

        return {
            "statistic": float(dw_stat),
            "interpretation": interpretation,
            "is_problematic": is_problematic,
            "critical_range": [1.5, 2.5],
        }

    def _breusch_pagan_test(
        self, residuals: np.ndarray, predicted_values: np.ndarray
    ) -> Dict[str, Any]:
        """Breusch-Pagan ê²€ì • (ë“±ë¶„ì‚°ì„± ê²€ì •)"""

        n = len(residuals)
        if n < 3:
            return {"is_heteroscedastic": False, "p_value": 0.5, "test_statistic": 0.0}

        # ì”ì°¨ ì œê³±ê³¼ ì˜ˆì¸¡ê°’ì˜ ìƒê´€ê³„ìˆ˜
        squared_residuals = residuals**2

        try:
            correlation, p_value = stats.pearsonr(squared_residuals, predicted_values)

            # LM í†µê³„ëŸ‰ (ê°„ëµí™”)
            lm_stat = n * correlation**2

            # ì„ê³„ê°’ ì„¤ì • (ê°„ëµí™”)
            is_heteroscedastic = abs(correlation) > 0.3 or p_value < 0.05

            return {
                "correlation": float(correlation),
                "p_value": float(p_value),
                "lm_statistic": float(lm_stat),
                "is_heteroscedastic": is_heteroscedastic,
                "interpretation": "ì´ë¶„ì‚°ì„± ë°œê²¬" if is_heteroscedastic else "ë“±ë¶„ì‚°ì„± ê°€ì • ë§Œì¡±",
            }
        except (ValueError, RuntimeError, TypeError) as e:
            logger.warning(f"Breusch-Pagan test failed: {e}")
            return {"is_heteroscedastic": False, "p_value": 0.5, "test_statistic": 0.0}

    def _shapiro_wilk_test(self, residuals: np.ndarray) -> Dict[str, Any]:
        """Shapiro-Wilk ê²€ì • (ì •ê·œì„± ê²€ì •)"""

        n = len(residuals)
        if n < 3:
            return {"is_normal": True, "p_value": 0.5, "statistic": 1.0}

        try:
            statistic, p_value = stats.shapiro(residuals)
            is_normal = p_value > 0.05

            return {
                "statistic": float(statistic),
                "p_value": float(p_value),
                "is_normal": is_normal,
                "interpretation": "ì •ê·œì„± ë§Œì¡±" if is_normal else "ì •ê·œì„± ìœ„ë°˜",
            }
        except (ValueError, RuntimeError, TypeError) as e:
            logger.warning(f"Shapiro-Wilk test failed: {e}")
            return {"is_normal": True, "p_value": 0.5, "statistic": 1.0}

    def _influence_diagnostics(
        self, x_data: np.ndarray, y_data: np.ndarray, regression_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì˜í–¥ë ¥ ì§„ë‹¨ (Cook's Distance, Leverage, DFFITS)"""

        n = len(x_data)
        p = 2  # íŒŒë¼ë¯¸í„° ê°œìˆ˜ (ì ˆí¸ + ê¸°ìš¸ê¸°)

        # ì„¤ê³„ í–‰ë ¬
        X = np.column_stack([np.ones(n), x_data])

        try:
            # Hat matrix (H = X(X'X)^(-1)X')
            XTX_inv = np.linalg.inv(X.T @ X)
            H = X @ XTX_inv @ X.T
            leverage = np.diag(H)

            # ì”ì°¨
            residuals = np.array(regression_result["residuals"])
            mse = regression_result["mse"]

            # Cook's Distance
            standardized_residuals = residuals / np.sqrt(mse * (1 - leverage))
            cooks_distance = (standardized_residuals**2 / p) * (
                leverage / (1 - leverage)
            )

            # DFFITS
            dffits = standardized_residuals * np.sqrt(leverage / (1 - leverage))

            # ì„ê³„ê°’
            leverage_threshold = 2 * p / n
            cooks_threshold = 4 / (n - p)
            dffits_threshold = 2 * np.sqrt(p / n)

            # ì˜í–¥ë ¥ ìˆëŠ” ê´€ì¸¡ì¹˜ íƒì§€
            high_leverage = leverage > leverage_threshold
            high_cooks = cooks_distance > cooks_threshold
            high_dffits = np.abs(dffits) > dffits_threshold

            influential = high_leverage | high_cooks | high_dffits

            return {
                "leverage": leverage.tolist(),
                "cooks_distance": cooks_distance.tolist(),
                "dffits": dffits.tolist(),
                "thresholds": {
                    "leverage": float(leverage_threshold),
                    "cooks_distance": float(cooks_threshold),
                    "dffits": float(dffits_threshold),
                },
                "influential_points": {
                    "high_leverage": np.where(high_leverage)[0].tolist(),
                    "high_cooks": np.where(high_cooks)[0].tolist(),
                    "high_dffits": np.where(high_dffits)[0].tolist(),
                    "any_influential": np.where(influential)[0].tolist(),
                },
                "influence_summary": {
                    "n_high_leverage": int(np.sum(high_leverage)),
                    "n_high_cooks": int(np.sum(high_cooks)),
                    "n_high_dffits": int(np.sum(high_dffits)),
                    "n_influential": int(np.sum(influential)),
                },
            }

        except (ValueError, np.linalg.LinAlgError, ZeroDivisionError) as e:
            # Numerical errors in influence diagnostics calculation
            logger.error(f"Influence diagnostics numerical error: {e}")
            print(f"Influence diagnostics numerical error: {str(e)}")
            return self._default_influence_result(n)
        except Exception as e:
            # Unexpected errors
            logger.exception(f"Unexpected influence diagnostics error: {e}")
            print(f"Influence diagnostics error: {str(e)}")
            return self._default_influence_result(n)

    def _advanced_outlier_detection(
        self,
        x_data: np.ndarray,
        y_data: np.ndarray,
        regression_result: Dict[str, Any],
        compound_names: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """ê³ ê¸‰ ì´ìƒì¹˜ íƒì§€"""

        n = len(x_data)
        residuals = np.array(regression_result["residuals"])
        std_residuals = np.array(regression_result["standardized_residuals"])

        # 1. í‘œì¤€í™” ì”ì°¨ ê¸°ë°˜ ì´ìƒì¹˜ (Â±3 ê¸°ì¤€)
        std_outliers = np.abs(std_residuals) >= self.outlier_threshold

        # 2. IQR ê¸°ë°˜ ì´ìƒì¹˜
        q1, q3 = np.percentile(residuals, [25, 75])
        iqr = q3 - q1
        iqr_outliers = (residuals < q1 - 1.5 * iqr) | (residuals > q3 + 1.5 * iqr)

        # 3. Modified Z-score (MAD ê¸°ë°˜)
        mad = np.median(np.abs(residuals - np.median(residuals)))
        modified_z_scores = (
            0.6745 * (residuals - np.median(residuals)) / mad
            if mad > 0
            else np.zeros_like(residuals)
        )
        mad_outliers = np.abs(modified_z_scores) > 3.5

        # 4. í†µí•© ì´ìƒì¹˜ íŒë³„
        combined_outliers = std_outliers | iqr_outliers | mad_outliers

        # ì´ìƒì¹˜ ìƒì„¸ ì •ë³´
        outlier_details = []
        for i in range(n):
            if combined_outliers[i]:
                outlier_info = {
                    "index": int(i),
                    "name": compound_names[i]
                    if compound_names and i < len(compound_names)
                    else f"Point_{i}",
                    "x_value": float(x_data[i]),
                    "y_value": float(y_data[i]),
                    "residual": float(residuals[i]),
                    "std_residual": float(std_residuals[i]),
                    "modified_z_score": float(modified_z_scores[i]),
                    "outlier_methods": [],
                }

                if std_outliers[i]:
                    outlier_info["outlier_methods"].append("Standardized Residual")
                if iqr_outliers[i]:
                    outlier_info["outlier_methods"].append("IQR Method")
                if mad_outliers[i]:
                    outlier_info["outlier_methods"].append("MAD Method")

                outlier_details.append(outlier_info)

        return {
            "outlier_indices": np.where(combined_outliers)[0].tolist(),
            "outlier_details": outlier_details,
            "outlier_summary": {
                "n_std_outliers": int(np.sum(std_outliers)),
                "n_iqr_outliers": int(np.sum(iqr_outliers)),
                "n_mad_outliers": int(np.sum(mad_outliers)),
                "n_total_outliers": int(np.sum(combined_outliers)),
                "outlier_percentage": float(np.sum(combined_outliers) / n * 100),
            },
            "thresholds": {
                "standardized_residual": self.outlier_threshold,
                "iqr_multiplier": 1.5,
                "mad_threshold": 3.5,
            },
        }

    def _test_regression_assumptions(
        self, residuals: List[float], predicted_values: List[float], x_data: np.ndarray
    ) -> Dict[str, Any]:
        """íšŒê·€ë¶„ì„ ê°€ì • ê²€ì •"""

        residuals = np.array(residuals)
        predicted_values = np.array(predicted_values)

        assumptions = {}

        # 1. ì„ í˜•ì„± (ì”ì°¨ vs ì˜ˆì¸¡ê°’ì˜ íŒ¨í„´)
        linearity_corr = (
            np.corrcoef(predicted_values, residuals)[0, 1] if len(residuals) > 1 else 0
        )
        assumptions["linearity"] = {
            "correlation": float(linearity_corr),
            "is_satisfied": abs(linearity_corr) < 0.1,
            "interpretation": "ì„ í˜•ì„± ë§Œì¡±" if abs(linearity_corr) < 0.1 else "ì„ í˜•ì„± ì˜ì‹¬",
        }

        # 2. ë…ë¦½ì„± (Durbin-Watson)
        dw_result = self._durbin_watson_test(residuals)
        assumptions["independence"] = {
            "durbin_watson": dw_result["statistic"],
            "is_satisfied": not dw_result["is_problematic"],
            "interpretation": dw_result["interpretation"],
        }

        # 3. ë“±ë¶„ì‚°ì„± (Breusch-Pagan)
        bp_result = self._breusch_pagan_test(residuals, predicted_values)
        assumptions["homoscedasticity"] = {
            "is_satisfied": not bp_result["is_heteroscedastic"],
            "test_result": bp_result,
            "interpretation": bp_result["interpretation"],
        }

        # 4. ì •ê·œì„± (Shapiro-Wilk)
        sw_result = self._shapiro_wilk_test(residuals)
        assumptions["normality"] = {
            "is_satisfied": sw_result["is_normal"],
            "test_result": sw_result,
            "interpretation": sw_result["interpretation"],
        }

        # ì¢…í•© í‰ê°€
        all_satisfied = all(
            [
                assumptions["linearity"]["is_satisfied"],
                assumptions["independence"]["is_satisfied"],
                assumptions["homoscedasticity"]["is_satisfied"],
                assumptions["normality"]["is_satisfied"],
            ]
        )

        assumptions["overall_assessment"] = {
            "all_assumptions_met": all_satisfied,
            "violated_assumptions": [
                name
                for name, test in assumptions.items()
                if isinstance(test, dict) and not test.get("is_satisfied", True)
            ],
        }

        return assumptions

    def _calculate_prediction_intervals(
        self, x_data: np.ndarray, y_data: np.ndarray, regression_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì˜ˆì¸¡ êµ¬ê°„ ê³„ì‚°"""

        n = len(x_data)
        if n < 3:
            return {"confidence_intervals": [], "prediction_intervals": []}

        slope = regression_result["slope"]
        intercept = regression_result["intercept"]
        mse = regression_result["mse"]

        # t ì„ê³„ê°’
        alpha = 1 - self.confidence_level
        t_critical = stats.t.ppf(1 - alpha / 2, n - 2)

        # ì„¤ê³„ í–‰ë ¬
        X = np.column_stack([np.ones(n), x_data])

        try:
            XTX_inv = np.linalg.inv(X.T @ X)

            confidence_intervals = []
            prediction_intervals = []

            for i, x_val in enumerate(x_data):
                # ì˜ˆì¸¡ê°’
                y_pred = slope * x_val + intercept

                # í‘œì¤€ì˜¤ì°¨
                x_vector = np.array([1, x_val])
                se_pred = np.sqrt(mse * x_vector.T @ XTX_inv @ x_vector)
                se_forecast = np.sqrt(mse * (1 + x_vector.T @ XTX_inv @ x_vector))

                # ì‹ ë¢°êµ¬ê°„ (í‰ê·  ì˜ˆì¸¡)
                ci_lower = y_pred - t_critical * se_pred
                ci_upper = y_pred + t_critical * se_pred

                # ì˜ˆì¸¡êµ¬ê°„ (ê°œë³„ ì˜ˆì¸¡)
                pi_lower = y_pred - t_critical * se_forecast
                pi_upper = y_pred + t_critical * se_forecast

                confidence_intervals.append(
                    {
                        "x": float(x_val),
                        "predicted": float(y_pred),
                        "lower": float(ci_lower),
                        "upper": float(ci_upper),
                    }
                )

                prediction_intervals.append(
                    {
                        "x": float(x_val),
                        "predicted": float(y_pred),
                        "lower": float(pi_lower),
                        "upper": float(pi_upper),
                    }
                )

            return {
                "confidence_level": self.confidence_level,
                "confidence_intervals": confidence_intervals,
                "prediction_intervals": prediction_intervals,
            }

        except (ValueError, np.linalg.LinAlgError, ZeroDivisionError) as e:
            # Numerical errors in prediction interval calculation
            logger.error(f"Prediction interval numerical error: {e}")
            print(f"Prediction interval numerical error: {str(e)}")
            return {"confidence_intervals": [], "prediction_intervals": []}
        except Exception as e:
            # Unexpected errors
            logger.exception(f"Unexpected prediction interval error: {e}")
            print(f"Prediction interval calculation error: {str(e)}")
            return {"confidence_intervals": [], "prediction_intervals": []}

    def _evaluate_model_quality(
        self,
        basic_regression: Dict[str, Any],
        residual_diagnostics: Dict[str, Any],
        assumption_tests: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ëª¨ë¸ í’ˆì§ˆ ì¢…í•© í‰ê°€"""

        r2 = basic_regression["r2"]
        adjusted_r2 = basic_regression["adjusted_r2"]
        f_p_value = basic_regression["f_p_value"]

        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100)
        quality_scores = {}

        # 1. ì„¤ëª…ë ¥ ì ìˆ˜ (RÂ² ê¸°ë°˜)
        quality_scores["explanatory_power"] = min(r2 * 100, 100)

        # 2. í†µê³„ì  ìœ ì˜ì„± ì ìˆ˜
        quality_scores["statistical_significance"] = (
            100 if f_p_value < 0.05 else 50 if f_p_value < 0.1 else 0
        )

        # 3. ê°€ì • ë§Œì¡±ë„ ì ìˆ˜
        assumptions_met = sum(
            [
                assumption_tests["linearity"]["is_satisfied"],
                assumption_tests["independence"]["is_satisfied"],
                assumption_tests["homoscedasticity"]["is_satisfied"],
                assumption_tests["normality"]["is_satisfied"],
            ]
        )
        quality_scores["assumption_compliance"] = (assumptions_met / 4) * 100

        # 4. ì”ì°¨ í’ˆì§ˆ ì ìˆ˜
        residual_quality = 100
        if residual_diagnostics["autocorrelation_detected"]:
            residual_quality -= 30
        if residual_diagnostics["heteroscedasticity_detected"]:
            residual_quality -= 25
        if residual_diagnostics["non_normality_detected"]:
            residual_quality -= 20
        quality_scores["residual_quality"] = max(residual_quality, 0)

        # ì¢…í•© ì ìˆ˜
        overall_score = np.mean(list(quality_scores.values()))

        # ë“±ê¸‰ íŒì •
        if overall_score >= 90:
            grade = "Excellent"
            reliability = "Very High"
        elif overall_score >= 80:
            grade = "Good"
            reliability = "High"
        elif overall_score >= 70:
            grade = "Acceptable"
            reliability = "Medium"
        elif overall_score >= 60:
            grade = "Poor"
            reliability = "Low"
        else:
            grade = "Unacceptable"
            reliability = "Very Low"

        return {
            "overall_score": float(overall_score),
            "grade": grade,
            "reliability": reliability,
            "quality_scores": {k: float(v) for k, v in quality_scores.items()},
            "meets_threshold": r2 >= self.r2_threshold,
            "recommendations": self._generate_recommendations(
                basic_regression, residual_diagnostics, assumption_tests
            ),
        }

    def _generate_recommendations(
        self,
        basic_regression: Dict[str, Any],
        residual_diagnostics: Dict[str, Any],
        assumption_tests: Dict[str, Any],
    ) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""

        recommendations = []

        # RÂ² ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        r2 = basic_regression["r2"]
        if r2 < 0.5:
            recommendations.append("ì„¤ëª…ë ¥ì´ ë‚®ìŠµë‹ˆë‹¤. ì¶”ê°€ ë³€ìˆ˜ë‚˜ ë¹„ì„ í˜• ëª¨ë¸ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        elif r2 < self.r2_threshold:
            recommendations.append("ì„¤ëª…ë ¥ì„ ë†’ì´ê¸° ìœ„í•´ ì´ìƒì¹˜ ì œê±°ë‚˜ ë³€ìˆ˜ ë³€í™˜ì„ ê²€í† í•´ë³´ì„¸ìš”.")

        # ê°€ì • ìœ„ë°˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if not assumption_tests["linearity"]["is_satisfied"]:
            recommendations.append("ì„ í˜•ì„± ê°€ì •ì´ ìœ„ë°˜ë©ë‹ˆë‹¤. ë¹„ì„ í˜• íšŒê·€ë‚˜ ë³€ìˆ˜ ë³€í™˜ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

        if not assumption_tests["independence"]["is_satisfied"]:
            recommendations.append("ë…ë¦½ì„± ê°€ì •ì´ ìœ„ë°˜ë©ë‹ˆë‹¤. ì‹œê³„ì—´ ëª¨ë¸ì´ë‚˜ ì¼ë°˜í™” ì„ í˜•ëª¨ë¸ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

        if not assumption_tests["homoscedasticity"]["is_satisfied"]:
            recommendations.append("ë“±ë¶„ì‚°ì„± ê°€ì •ì´ ìœ„ë°˜ë©ë‹ˆë‹¤. ê°€ì¤‘ìµœì†Œì œê³±ë²•ì´ë‚˜ ë¡œë²„ìŠ¤íŠ¸ íšŒê·€ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")

        if not assumption_tests["normality"]["is_satisfied"]:
            recommendations.append("ì •ê·œì„± ê°€ì •ì´ ìœ„ë°˜ë©ë‹ˆë‹¤. ë¹„ëª¨ìˆ˜ì  ë°©ë²•ì´ë‚˜ ë³€ìˆ˜ ë³€í™˜ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

        # ì´ìƒì¹˜ ê´€ë ¨ ê¶Œì¥ì‚¬í•­
        if residual_diagnostics.get("outlier_detected", False):
            recommendations.append("ì´ìƒì¹˜ê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„° í’ˆì§ˆì„ í™•ì¸í•˜ê³  ì´ìƒì¹˜ ì œê±°ë¥¼ ê²€í† í•´ë³´ì„¸ìš”.")

        if not recommendations:
            recommendations.append("íšŒê·€ëª¨ë¸ì´ ì–‘í˜¸í•œ í’ˆì§ˆì„ ë³´ì…ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")

        return recommendations

    def _generate_analysis_summary(
        self,
        basic_regression: Dict[str, Any],
        model_quality: Dict[str, Any],
        outlier_analysis: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ë¶„ì„ ìš”ì•½ ìƒì„±"""

        return {
            "model_equation": basic_regression["equation"],
            "r_squared": basic_regression["r2"],
            "adjusted_r_squared": basic_regression["adjusted_r2"],
            "p_value": basic_regression["f_p_value"],
            "sample_size": basic_regression["n_observations"],
            "quality_grade": model_quality["grade"],
            "overall_score": model_quality["overall_score"],
            "outliers_detected": outlier_analysis["outlier_summary"][
                "n_total_outliers"
            ],
            "outlier_percentage": outlier_analysis["outlier_summary"][
                "outlier_percentage"
            ],
            "meets_quality_threshold": model_quality["meets_threshold"],
            "key_recommendations": model_quality["recommendations"][:3],  # ìƒìœ„ 3ê°œ ê¶Œì¥ì‚¬í•­
        }

    def _minimal_regression_result(
        self, x_data: np.ndarray, y_data: np.ndarray
    ) -> Dict[str, Any]:
        """ìµœì†Œ ë°ì´í„°ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ íšŒê·€ ê²°ê³¼"""

        if len(x_data) == 0:
            return self._empty_regression_result()

        basic_regression = self._perform_ols_regression(x_data, y_data)

        return {
            "basic_regression": basic_regression,
            "model_quality": {
                "overall_score": 50.0,
                "grade": "Insufficient Data",
                "reliability": "Low",
                "meets_threshold": False,
            },
            "analysis_summary": {
                "model_equation": basic_regression["equation"],
                "r_squared": basic_regression["r2"],
                "sample_size": len(x_data),
                "key_recommendations": ["ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."],
            },
        }

    def _empty_regression_result(self) -> Dict[str, Any]:
        """ë¹ˆ ë°ì´í„°ë¥¼ ìœ„í•œ ê¸°ë³¸ ê²°ê³¼"""

        return {
            "basic_regression": {"equation": "RT = 0.0000 * Log_P + 0.0000", "r2": 0.0},
            "model_quality": {
                "overall_score": 0.0,
                "grade": "No Data",
                "reliability": "None",
            },
            "analysis_summary": {"key_recommendations": ["ë°ì´í„°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."]},
        }

    def _error_regression_result(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ ê²°ê³¼"""

        return {
            "error": True,
            "error_message": error_message,
            "basic_regression": {"equation": "Error in calculation", "r2": 0.0},
            "model_quality": {
                "overall_score": 0.0,
                "grade": "Error",
                "reliability": "None",
            },
            "analysis_summary": {"key_recommendations": ["ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]},
        }

    def _default_influence_result(self, n: int) -> Dict[str, Any]:
        """ì˜í–¥ë ¥ ì§„ë‹¨ ê¸°ë³¸ ê²°ê³¼"""

        return {
            "leverage": [0.0] * n,
            "cooks_distance": [0.0] * n,
            "dffits": [0.0] * n,
            "influential_points": {"any_influential": []},
            "influence_summary": {"n_influential": 0},
        }
