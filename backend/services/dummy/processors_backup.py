"""
Dummy Data Processor - ì‹¤ì œ ë¶„ì„ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜
ê°œë°œ ë° í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ í´ë˜ìŠ¤
"""

import pandas as pd
from typing import Dict, Any


class DummyGangliosideDataProcessor:
    """ë”ë¯¸ ë°ì´í„° í”„ë¡œì„¸ì„œ - ì‹¤ì œ ë¶„ì„ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜"""
    
    def __init__(self):
        self.r2_threshold = 0.99
        self.outlier_threshold = 3.0
        self.rt_tolerance = 0.1
        print("ğŸ§ª Dummy Ganglioside Data Processor ì´ˆê¸°í™”")
    
    def update_settings(self, outlier_threshold=None, r2_threshold=None, rt_tolerance=None):
        """ë¶„ì„ ì„¤ì • ì—…ë°ì´íŠ¸"""
        if outlier_threshold is not None:
            self.outlier_threshold = outlier_threshold
        if r2_threshold is not None:
            self.r2_threshold = r2_threshold
        if rt_tolerance is not None:
            self.rt_tolerance = rt_tolerance
        print(f"âš™ï¸ ë”ë¯¸ ì„¤ì • ì—…ë°ì´íŠ¸: outlier={self.outlier_threshold}, r2={self.r2_threshold}, rt={self.rt_tolerance}")
    
    def get_settings(self):
        """í˜„ì¬ ì„¤ì • ë°˜í™˜"""
        return {
            'outlier_threshold': self.outlier_threshold,
            'r2_threshold': self.r2_threshold,
            'rt_tolerance': self.rt_tolerance
        }
        
    def process_data(self, df: pd.DataFrame, data_type: str = "Porcine") -> Dict[str, Any]:
        """ì‹¤ì œ 5ê°€ì§€ ê·œì¹™ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í–¥ìƒëœ ë¶„ì„ (ì„¤ì • ë°˜ì˜)"""
        
        print(f"ğŸ”¬ ë”ë¯¸ ë¶„ì„ ì‹¤í–‰: threshold={self.outlier_threshold}, r2={self.r2_threshold}, rt={self.rt_tolerance}")
        
        # ë°ì´í„° ì „ì²˜ë¦¬ - ê°œì„ ëœ ì ‘ë‘ì‚¬ ì¶”ì¶œ
        df = df.copy()
        
        # ë³µí•© ì ‘ë‘ì‚¬ ì²˜ë¦¬ (GD1+HexNAc, GM1+HexNAc ë“±)
        def extract_ganglioside_prefix(name):
            # GD1+HexNAc, GM1+HexNAc ë“±ì˜ ë³µí•© ì ‘ë‘ì‚¬ ë¨¼ì € í™•ì¸
            if '+HexNAc' in name:
                base_prefix = name.split('+HexNAc')[0]
                return f"{base_prefix}+HexNAc"
            # ê¸°ë³¸ ganglioside ì ‘ë‘ì‚¬ (GD1a, GD1b, GM1a, GM3, GD3, GT1b ë“±)
            elif any(gtype in name for gtype in ['GD1a', 'GD1b', 'GM1a', 'GM1b', 'GM2', 'GM3', 'GD2', 'GD3', 'GT1a', 'GT1b', 'GT1c']):
                # ì •í™•í•œ ganglioside íƒ€ì… ì¶”ì¶œ
                for gtype in ['GD1a', 'GD1b', 'GM1a', 'GM1b', 'GM2', 'GM3', 'GD2', 'GD3', 'GT1a', 'GT1b', 'GT1c']:
                    if name.startswith(gtype):
                        return gtype
            # ì¼ë°˜ì ì¸ ì ‘ë‘ì‚¬ ì¶”ì¶œ (ê´„í˜¸ ì•ê¹Œì§€)
            else:
                return name.split('(')[0] if '(' in name else name
            return name.split('(')[0] if '(' in name else name
        
        df['prefix'] = df['Name'].apply(extract_ganglioside_prefix)
        df['suffix'] = df['Name'].str.extract(r'\(([^)]+)\)')[0]
        
        print(f"ğŸ“Š ì ‘ë‘ì‚¬ ê·¸ë£¹ ë¶„ì„: {df['prefix'].value_counts().to_dict()}")
        
        # íŠ¹ë³„ ê·œì¹™: GD1a/GD1b ìë™ ë¶„ë¥˜
        auto_valid_types = ['GD1a', 'GD1b']
        auto_valid_compounds = []
        
        for gtype in auto_valid_types:
            gtype_compounds = df[df['prefix'] == gtype]
            if len(gtype_compounds) > 0:
                print(f"âœ… {gtype} ìë™ ë¶„ë¥˜: {len(gtype_compounds)}ê°œ í™”í•©ë¬¼")
                for _, row in gtype_compounds.iterrows():
                    row_dict = row.to_dict()
                    row_dict['auto_classification'] = f'Rule: {gtype} auto-valid'
                    row_dict['forced_valid'] = True
                    auto_valid_compounds.append(row_dict)
        
        # ê·œì¹™ 1: ì ‘ë‘ì‚¬ë³„ íšŒê·€ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜ (ê°œì„ ëœ RÂ² ì„ê³„ê°’ ì ìš©)
        regression_results = {}
        valid_compounds = []
        outliers = []
        
        # ë¨¼ì € ìë™ ë¶„ë¥˜ëœ í™”í•©ë¬¼ë“¤ì„ valid_compoundsì— ì¶”ê°€
        valid_compounds.extend(auto_valid_compounds)
        print(f"ğŸ¯ ìë™ ë¶„ë¥˜ ì™„ë£Œ: {len(auto_valid_compounds)}ê°œ")
        
        # ë¨¼ì € ëª¨ë“  Anchor ë°ì´í„°í¬ì¸íŠ¸ë¥¼ ì°¸ê°’(ìœ íš¨)ìœ¼ë¡œ ë¶„ë¥˜
        anchor_data = df[df['Anchor'] == 'T']
        print(f"ğŸ¯ Anchor ë°ì´í„°í¬ì¸íŠ¸ {len(anchor_data)}ê°œë¥¼ ì°¸ê°’ìœ¼ë¡œ ë¶„ë¥˜")
        
        for prefix in df['prefix'].unique():
            if pd.isna(prefix):
                continue
                
            prefix_group = df[df['prefix'] == prefix]
            anchor_compounds = prefix_group[prefix_group['Anchor'] == 'T']
            
            # ìë™ ë¶„ë¥˜ëœ ê·¸ë£¹ì€ ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì²˜ë¦¬ë¨)
            if prefix in auto_valid_types:
                print(f"â­ï¸  {prefix}: ìë™ ë¶„ë¥˜ë¡œ ê±´ë„ˆë›°ê¸°")
                continue
            
            if len(anchor_compounds) >= 1 or len(prefix_group) >= 2:  # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì™„í™”
                print(f"ğŸ“Š {prefix} ê·¸ë£¹: {len(anchor_compounds)}ê°œ Anchor, {len(prefix_group)}ê°œ ì´ í™”í•©ë¬¼")
                
                # ê°œì„ ëœ RÂ² ê³„ì‚° - ìœ„ìŒì„± ê°ì†Œë¥¼ ìœ„í•´ ë” ê´€ëŒ€í•œ ê¸°ì¤€
                base_r2 = 0.92 + (len(anchor_compounds) * 0.01)  # ê¸°ë³¸ RÂ² ìƒí–¥
                
                # íŠ¹ë³„í•œ ì ‘ë‘ì‚¬ ê·¸ë£¹ì— ëŒ€í•œ ë³´ë„ˆìŠ¤ RÂ²
                if '+HexNAc' in prefix:
                    base_r2 += 0.03  # HexNAc ê·¸ë£¹ì€ ë” ë†’ì€ ì‹ ë¢°ë„
                    print(f"  ğŸ§ª {prefix}: HexNAc ê·¸ë£¹ ë³´ë„ˆìŠ¤ RÂ² ì ìš©")
                
                # ì„¤ì •ëœ ì„ê³„ê°’ì— ë”°ë¼ ì¡°ì • - ë” ê´€ëŒ€í•˜ê²Œ
                if self.r2_threshold > 0.99:
                    r2 = min(base_r2 + 0.01, 0.999)  # ë†’ì€ ì„ê³„ê°’ì¼ ë•Œ
                elif self.r2_threshold < 0.95:
                    r2 = max(base_r2, 0.88)   # ë‚®ì€ ì„ê³„ê°’ì¼ ë•Œë„ í•©ë¦¬ì  ìˆ˜ì¤€ ìœ ì§€
                else:
                    r2 = base_r2
                
                slope = -0.5 + (hash(prefix) % 100) / 100
                intercept = 8.0 + (hash(prefix) % 50) / 10
                
                # ë” ê´€ëŒ€í•œ RÂ² ì„ê³„ê°’ ê²€ì‚¬ ì ìš©
                effective_threshold = max(self.r2_threshold - 0.02, 0.85)  # ì„ê³„ê°’ì„ ì•½ê°„ ì™„í™”
                
                if r2 >= effective_threshold:
                # ê°œì„ ëœ RÂ² ê³„ì‚° - ìœ„ìŒì„± ê°ì†Œë¥¼ ìœ„í•´ ë” ê´€ëŒ€í•œ ê¸°ì¤€
                base_r2 = 0.92 + (len(anchor_compounds) * 0.01)  # ê¸°ë³¸ RÂ² ìƒí–¥
                
                # íŠ¹ë³„í•œ ì ‘ë‘ì‚¬ ê·¸ë£¹ì— ëŒ€í•œ ë³´ë„ˆìŠ¤ RÂ²
                if '+HexNAc' in prefix:
                    base_r2 += 0.03  # HexNAc ê·¸ë£¹ì€ ë” ë†’ì€ ì‹ ë¢°ë„
                    print(f"  ğŸ§ª {prefix}: HexNAc ê·¸ë£¹ ë³´ë„ˆìŠ¤ RÂ² ì ìš©")
                
                # ì„¤ì •ëœ ì„ê³„ê°’ì— ë”°ë¼ ì¡°ì • - ë” ê´€ëŒ€í•˜ê²Œ
                if self.r2_threshold > 0.99:
                    r2 = min(base_r2 + 0.01, 0.999)  # ë†’ì€ ì„ê³„ê°’ì¼ ë•Œ
                elif self.r2_threshold < 0.95:
                    r2 = max(base_r2, 0.88)   # ë‚®ì€ ì„ê³„ê°’ì¼ ë•Œë„ í•©ë¦¬ì  ìˆ˜ì¤€ ìœ ì§€
                else:
                    r2 = base_r2
                
                slope = -0.5 + (hash(prefix) % 100) / 100
                intercept = 8.0 + (hash(prefix) % 50) / 10
                
                # ë” ê´€ëŒ€í•œ RÂ² ì„ê³„ê°’ ê²€ì‚¬ ì ìš©
                effective_threshold = max(self.r2_threshold - 0.02, 0.85)  # ì„ê³„ê°’ì„ ì•½ê°„ ì™„í™”
                
                if r2 >= effective_threshold:
                    regression_results[prefix] = {
                        'slope': slope,
                        'intercept': intercept,
                        'r2': r2,
                        'n_samples': len(prefix_group),
                        'anchor_count': len(anchor_compounds),
                        'equation': f'RT = {slope:.4f} * Log P + {intercept:.4f}',
                        'p_value': 0.001,
                        'passes_threshold': True,
                        'effective_threshold': effective_threshold
                    }
                    
                    # ê° í™”í•©ë¬¼ ì²˜ë¦¬ (Anchor ìš°ì„  ì²˜ë¦¬)
                    for _, row in prefix_group.iterrows():
                        row_dict = row.to_dict()
                        predicted_rt = slope * row['Log P'] + intercept
                        residual = row['RT'] - predicted_rt
                        
                        row_dict['predicted_rt'] = predicted_rt
                        row_dict['residual'] = residual
                        
                        # í‘œì¤€í™” ì”ì°¨ ê³„ì‚° - ë” ê´€ëŒ€í•œ ê¸°ì¤€
                        std_residual = residual / 0.15  # í‘œì¤€í¸ì°¨ë¥¼ ë” í¬ê²Œ ì„¤ì •í•˜ì—¬ ê´€ëŒ€í•˜ê²Œ
                        row_dict['std_residual'] = std_residual
                        
                        # â­ Anchor ë°ì´í„°í¬ì¸íŠ¸ëŠ” í•­ìƒ ìœ íš¨ë¡œ ë¶„ë¥˜ (ì°¸ê°’ ê°•ì œ)
                        if row['Anchor'] == 'T':
                            row_dict['anchor_status'] = 'Reference Point'
                            row_dict['forced_valid'] = True
                            valid_compounds.append(row_dict)
                            print(f"  âœ… {row['Name']}: Anchorë¡œ ê°•ì œ ìœ íš¨ ì²˜ë¦¬")
                        else:
                            # ì¼ë°˜ í™”í•©ë¬¼ì— ë” ê´€ëŒ€í•œ ì´ìƒì¹˜ ê²€ì‚¬ ì ìš©
                            effective_outlier_threshold = self.outlier_threshold + 0.5  # ê´€ëŒ€í•œ ì„ê³„ê°’
                            if abs(std_residual) >= effective_outlier_threshold:
                                row_dict['outlier_reason'] = f'Rule 1: |Std residual| = {abs(std_residual):.2f} >= {effective_outlier_threshold}'
                                outliers.append(row_dict)
                            else:
                                valid_compounds.append(row_dict)
                                print(f"  âœ… {row['Name']}: ìœ íš¨ í™”í•©ë¬¼ë¡œ ë¶„ë¥˜ (ê´€ëŒ€í•œ ê¸°ì¤€)")
                                
                else:
                    # RÂ² ì„ê³„ê°’ ë¯¸ë‹¬ì´ì§€ë§Œ AnchorëŠ” ì—¬ì „íˆ ì²˜ë¦¬
                    regression_results[prefix] = {
                        'slope': slope,
                        'intercept': intercept,
                        'r2': r2,
                        'n_samples': len(prefix_group),
                        'anchor_count': len(anchor_compounds),
                        'equation': f'RT = {slope:.4f} * Log P + {intercept:.4f}',
                        'p_value': 0.1,
                        'passes_threshold': False,
                        'effective_threshold': effective_threshold
                    }
                    
                    print(f"  âš ï¸ {prefix} ê·¸ë£¹: RÂ² = {r2:.3f} < {effective_threshold:.3f}, í•˜ì§€ë§Œ AnchorëŠ” ìœ íš¨ ì²˜ë¦¬")
                    
                    for _, row in prefix_group.iterrows():
                        row_dict = row.to_dict()
                        
                        # â­ AnchorëŠ” RÂ² ì„ê³„ê°’ê³¼ ê´€ê³„ì—†ì´ í•­ìƒ ìœ íš¨ë¡œ ë¶„ë¥˜
                        if row['Anchor'] == 'T':
                            row_dict['anchor_status'] = 'Reference Point (Low RÂ²)'
                            row_dict['forced_valid'] = True
                            # AnchorëŠ” RÂ² ë‚®ì•„ë„ ìœ íš¨í•˜ë¯€ë¡œ valid_compoundsì— ì¶”ê°€
                            valid_compounds.append(row_dict)
                            print(f"  âœ… {row['Name']}: Anchorë¡œ ê°•ì œ ìœ íš¨ ì²˜ë¦¬ (ë‚®ì€ RÂ² ë¬´ì‹œ)")
                        else:
                            # ì¼ë°˜ í™”í•©ë¬¼ì€ RÂ² ì„ê³„ê°’ ë¯¸ë‹¬ë¡œ ì´ìƒì¹˜ ì²˜ë¦¬
                            row_dict['outlier_reason'] = f'Rule 1: Low RÂ² = {r2:.3f} < {effective_threshold:.3f}'
                            outliers.append(row_dict)
                    for _, row in prefix_group.iterrows():
                        row_dict = row.to_dict()
                        predicted_rt = slope * row['Log P'] + intercept
                        residual = row['RT'] - predicted_rt
                        
                        row_dict['predicted_rt'] = predicted_rt
                        row_dict['residual'] = residual
                        
                        # í‘œì¤€í™” ì”ì°¨ ê³„ì‚°
                        std_residual = residual / 0.1
                        row_dict['std_residual'] = std_residual
                        
                        # â­ Anchor ë°ì´í„°í¬ì¸íŠ¸ëŠ” í•­ìƒ ìœ íš¨ë¡œ ë¶„ë¥˜ (ì°¸ê°’ ê°•ì œ)
                        if row['Anchor'] == 'T':
                            row_dict['anchor_status'] = 'Reference Point'
                            row_dict['forced_valid'] = True
                            valid_compounds.append(row_dict)
                            print(f"  âœ… {row['Name']}: Anchorë¡œ ê°•ì œ ìœ íš¨ ì²˜ë¦¬")
                        else:
                            # ì¼ë°˜ í™”í•©ë¬¼ë§Œ ì´ìƒì¹˜ ê²€ì‚¬ ì ìš©
                            if abs(std_residual) >= self.outlier_threshold:
                                row_dict['outlier_reason'] = f'Rule 1: |Std residual| = {abs(std_residual):.2f} >= {self.outlier_threshold}'
                                outliers.append(row_dict)
                            else:
                                valid_compounds.append(row_dict)
                else:
                    # RÂ² ì„ê³„ê°’ ë¯¸ë‹¬ì´ì§€ë§Œ AnchorëŠ” ì—¬ì „íˆ ì²˜ë¦¬
                    regression_results[prefix] = {
                        'slope': slope,
                        'intercept': intercept,
                        'r2': r2,
                        'n_samples': len(prefix_group),
                        'anchor_count': len(anchor_compounds),
                        'equation': f'RT = {slope:.4f} * Log P + {intercept:.4f}',
                        'p_value': 0.1,
                        'passes_threshold': False
                    }
                    
                    print(f"  âš ï¸ {prefix} ê·¸ë£¹: RÂ² = {r2:.3f} < {self.r2_threshold}, í•˜ì§€ë§Œ AnchorëŠ” ìœ íš¨ ì²˜ë¦¬")
                    
                    for _, row in prefix_group.iterrows():
                        row_dict = row.to_dict()
                        
                        # â­ AnchorëŠ” RÂ² ì„ê³„ê°’ê³¼ ê´€ê³„ì—†ì´ í•­ìƒ ìœ íš¨ë¡œ ë¶„ë¥˜
                        if row['Anchor'] == 'T':
                            row_dict['anchor_status'] = 'Reference Point (Low RÂ²)'
                            row_dict['forced_valid'] = True
                            # AnchorëŠ” RÂ² ë‚®ì•„ë„ ìœ íš¨í•˜ë¯€ë¡œ valid_compoundsì— ì¶”ê°€
                            valid_compounds.append(row_dict)
                            print(f"  âœ… {row['Name']}: Anchorë¡œ ê°•ì œ ìœ íš¨ ì²˜ë¦¬ (ë‚®ì€ RÂ² ë¬´ì‹œ)")
                        else:
                            # ì¼ë°˜ í™”í•©ë¬¼ì€ RÂ² ì„ê³„ê°’ ë¯¸ë‹¬ë¡œ ì´ìƒì¹˜ ì²˜ë¦¬
                            row_dict['outlier_reason'] = f'Rule 1: Low RÂ² = {r2:.3f} < {self.r2_threshold}'
                            outliers.append(row_dict)
        
        # ê·œì¹™ 4: O-acetylation ë¶„ì„
        oacetyl_compounds = df[df['prefix'].str.contains('OAc', na=False)]
        valid_oacetyl = []
        invalid_oacetyl = []
        
        for _, row in oacetyl_compounds.iterrows():
            row_dict = row.to_dict()
            # 90% í™•ë¥ ë¡œ ìœ íš¨í•œ OAc íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜
            if hash(row['Name']) % 10 < 9:
                row_dict['rt_increase'] = 0.2 + (hash(row['Name']) % 50) / 100
                valid_oacetyl.append(row_dict)
            else:
                row_dict['outlier_reason'] = 'Rule 4: O-acetylation should increase RT'
                invalid_oacetyl.append(row_dict)
        
        # ìµœì¢… í†µê³„ ê³„ì‚°
        total_compounds = len(df)
        anchor_compounds = len(df[df['Anchor'] == 'T'])
        final_valid = len(valid_compounds)
        final_outliers = len(outliers) + len(invalid_oacetyl)
        success_rate = (final_valid / total_compounds) * 100 if total_compounds > 0 else 0
        
        # Anchor í†µê³„ í™•ì¸
        anchor_in_valid = len([c for c in valid_compounds if c.get('Anchor') == 'T'])
        anchor_success_rate = (anchor_in_valid / anchor_compounds) * 100 if anchor_compounds > 0 else 0
        
        # ì„¤ì • ì˜í–¥ë„ ê³„ì‚°
        setting_impact = {
            'outlier_strictness': 'High' if self.outlier_threshold >= 3.0 else 'Medium' if self.outlier_threshold >= 2.0 else 'Low',
            'r2_strictness': 'Very High' if self.r2_threshold >= 0.99 else 'High' if self.r2_threshold >= 0.95 else 'Medium',
            'rt_precision': 'High' if self.rt_tolerance <= 0.1 else 'Medium' if self.rt_tolerance <= 0.2 else 'Low',
            'expected_success_rate': success_rate,
            'anchor_preservation': anchor_success_rate
        }
        
        print(f"ğŸ“Š ë”ë¯¸ ë¶„ì„ ê²°ê³¼: {final_valid}/{total_compounds} ìœ íš¨ ({success_rate:.1f}%)")
        print(f"ğŸ¯ Anchor ë³´ì¡´ë¥ : {anchor_in_valid}/{anchor_compounds} ({anchor_success_rate:.1f}%) - ëª¨ë“  AnchorëŠ” ì°¸ê°’ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨")
        
        return {
            "statistics": {
                "total_compounds": total_compounds,
                "anchor_compounds": anchor_compounds,
                "anchor_in_valid": anchor_in_valid,
                "anchor_success_rate": anchor_success_rate,
                "valid_compounds": final_valid,
                "outliers": final_outliers,
                "success_rate": success_rate,
                "rule_breakdown": {
                    "rule1_regression": len(valid_compounds),
                    "rule4_oacetylation": len(valid_oacetyl),
                    "rule5_rt_filtering": len(df),
                    "rule1_outliers": len(outliers),
                    "rule4_outliers": len(invalid_oacetyl),
                    "rule5_outliers": 0,
                    "anchor_forced_valid": anchor_in_valid
                },
                "anchor_analysis": {
                    "total_anchors": anchor_compounds,
                    "valid_anchors": anchor_in_valid,
                    "preservation_rate": anchor_success_rate,
                    "note": "All Anchors should be classified as valid (reference points)"
                }
            },
            "valid_compounds": valid_compounds,
            "outliers": outliers + invalid_oacetyl,
            "regression_analysis": regression_results,
            "setting_impact": setting_impact,
            "status": f"Dummy Analysis - Thresholds: Outlier={self.outlier_threshold}, RÂ²={self.r2_threshold}, RT=Â±{self.rt_tolerance}",
            "target_achievement": f"{final_valid}/{total_compounds} compounds identified",
            "analysis_summary": {
                "data_quality": 'High' if success_rate >= 90 else 'Medium' if success_rate >= 70 else 'Low',
                "settings_applied": True
            }
        }


class DummyVisualizationService:
    """ë”ë¯¸ ì‹œê°í™” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        print("ğŸ“Š Dummy Visualization Service ì´ˆê¸°í™”")
    
    def create_all_plots(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ë”ë¯¸ ì‹œê°í™” ìƒì„±"""
        return {
            "message": "ë”ë¯¸ ì‹œê°í™” ê¸°ëŠ¥ ì¤€ë¹„ ì¤‘",
            "available_plots": [
                "regression_plots",
                "residual_analysis", 
                "outlier_detection",
                "rt_distribution",
                "success_rate_summary"
            ]
        }
