"""
Analysis API Routes - ë°ì´í„° ë¶„ì„ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸ë“¤
"""

import io
import traceback
from datetime import datetime

import pandas as pd
import numpy as np
from flask import Blueprint, jsonify, request, send_file

# ì „ì—­ ë³€ìˆ˜ë¡œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ê°€ì ¸ì˜¬ ì˜ˆì •
processor = None
regression_analyzer = None
visualization_service = None

# Blueprint ìƒì„±
analysis_bp = Blueprint('analysis', __name__, url_prefix='/api')


def init_services(ganglioside_processor, reg_analyzer, vis_service):
    """ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì´ˆê¸°í™”"""
    global processor, regression_analyzer, visualization_service
    processor = ganglioside_processor
    regression_analyzer = reg_analyzer
    visualization_service = vis_service


def convert_to_serializable(obj):
    """NumPy/pandas ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
    if isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    elif isinstance(obj, (np.integer, np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif pd.isna(obj):
        return None
    return obj


@analysis_bp.route("/upload", methods=["POST"])
def upload_csv():
    """CSV íŒŒì¼ ì—…ë¡œë“œ ë° ê¸°ë³¸ ê²€ì¦"""
    try:
        if "file" not in request.files:
            return jsonify({"error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        file = request.files["file"]
        if file.filename == "":
            return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        if not file.filename.lower().endswith('.csv'):
            return jsonify({"error": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."}), 400

        # CSV íŒŒì¼ ì½ê¸°
        try:
            df = pd.read_csv(file)
        except Exception as e:
            return jsonify({"error": f"CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"}), 400

        # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì‚¬
        required_columns = ["Name", "RT", "Volume"]
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            return jsonify({
                "error": f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}"
            }), 400

        # ê¸°ë³¸ í†µê³„ ì •ë³´ ë°˜í™˜
        file_info = {
            "filename": file.filename,
            "rows": len(df),
            "columns": list(df.columns),
            "preview": df.head().to_dict('records'),
            "upload_time": datetime.now().isoformat()
        }

        return jsonify({
            "message": "íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ",
            "file_info": file_info
        })

    except Exception as e:
        print(f"Upload error: {str(e)}")
        return jsonify(
            {"error": f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
        ), 500


@analysis_bp.route("/analyze", methods=["POST"])
def analyze_data():
    """ë°ì´í„° ë¶„ì„ ì‹¤í–‰"""
    try:
        # íŒŒì¼ ë° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        if "file" not in request.files:
            return jsonify({"error": "ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        file = request.files["file"]
        data_type = request.form.get("data_type", "Porcine")
        outlier_threshold = float(request.form.get("outlier_threshold", 3.0))
        r2_threshold = float(request.form.get("r2_threshold", 0.99))
        rt_tolerance = float(request.form.get("rt_tolerance", 0.1))

        # CSV íŒŒì¼ ì½ê¸°
        df = pd.read_csv(file)
        print(f"ğŸ”¬ ë¶„ì„ ì‹œì‘: {len(df)}ê°œ í™”í•©ë¬¼, ëª¨ë“œ: {data_type}")

        # ì„¤ì • ì—…ë°ì´íŠ¸
        processor.update_settings(
            outlier_threshold=outlier_threshold,
            r2_threshold=r2_threshold,
            rt_tolerance=rt_tolerance,
        )

        # ë°ì´í„° ë¶„ì„ ì‹¤í–‰
        results = processor.process_data(df, data_type)

        # ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serialized_results = convert_to_serializable(results)

        return jsonify({
            "message": "ë¶„ì„ ì™„ë£Œ",
            "results": serialized_results,
            "settings": {
                "data_type": data_type,
                "outlier_threshold": outlier_threshold,
                "r2_threshold": r2_threshold,
                "rt_tolerance": rt_tolerance,
            },
            "analysis_time": datetime.now().isoformat()
        })

    except Exception as e:
        error_msg = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"Analysis error: {error_msg}")
        print(f"Traceback: {traceback.format_exc()}")
        return jsonify({"error": error_msg}), 500


@analysis_bp.route("/sample-test", methods=["POST"])
def sample_test():
    """ìƒ˜í”Œ ë°ì´í„° í…ŒìŠ¤íŠ¸"""
    try:
        # ìš”ì²­ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        data = request.get_json()
        if not data:
            return jsonify({"error": "JSON ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        data_type = data.get("data_type", "Porcine")
        outlier_threshold = float(data.get("outlier_threshold", 3.0))
        r2_threshold = float(data.get("r2_threshold", 0.99))
        rt_tolerance = float(data.get("rt_tolerance", 0.1))

        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_data = pd.DataFrame({
            "Name": [
                "GD1a(36:1;O2)",
                "GM1a(36:1;O2)",
                "GM3(36:1;O2)",
                "GD3(36:1;O2)",
                "GT1b(34:1;O2)"
            ],
            "RT": [9.572, 10.452, 10.606, 10.126, 8.701],
            "Volume": [1000000, 500000, 2000000, 800000, 1200000]
        })

        print(f"ğŸ”¬ ë¶„ì„ ì‹œì‘: {len(sample_data)}ê°œ í™”í•©ë¬¼, ëª¨ë“œ: {data_type}")

        # ì„¤ì • ì—…ë°ì´íŠ¸
        processor.update_settings(
            outlier_threshold=outlier_threshold,
            r2_threshold=r2_threshold,
            rt_tolerance=rt_tolerance,
        )

        # ë°ì´í„° ë¶„ì„ ì‹¤í–‰
        results = processor.process_data(sample_data, data_type)

        # ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serialized_results = convert_to_serializable(results)

        return jsonify({
            "message": "ìƒ˜í”Œ ë°ì´í„° ë¶„ì„ ì™„ë£Œ",
            "results": serialized_results,
            "settings": {
                "data_type": data_type,
                "outlier_threshold": outlier_threshold,
                "r2_threshold": r2_threshold,
                "rt_tolerance": rt_tolerance,
            },
            "sample_data": sample_data.to_dict('records'),
            "analysis_time": datetime.now().isoformat()
        })

    except Exception as e:
        error_msg = f"ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        print(f"Sample test error: {error_msg}")
        return jsonify({"error": error_msg}), 500


@analysis_bp.route("/download-results", methods=["POST"])
def download_results():
    """ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        data = request.get_json()
        if not data or "results" not in data:
            return jsonify({"error": "ë¶„ì„ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        results = data["results"]

        # CSV í˜•íƒœë¡œ ë³€í™˜
        output_data = []

        # ìœ íš¨í•œ í™”í•©ë¬¼ë“¤
        if "valid_compounds" in results:
            for compound in results["valid_compounds"]:
                output_data.append({
                    "Name": compound.get("Name", ""),
                    "RT": compound.get("RT", ""),
                    "Volume": compound.get("Volume", ""),
                    "Classification": "Valid",
                    "Log P": compound.get("Log P", ""),
                    "Prefix": compound.get("prefix", ""),
                    "Suffix": compound.get("suffix", "")
                })

        # ì´ìƒì¹˜ë“¤
        if "outliers" in results:
            for outlier in results["outliers"]:
                output_data.append({
                    "Name": outlier.get("Name", ""),
                    "RT": outlier.get("RT", ""),
                    "Volume": outlier.get("Volume", ""),
                    "Classification": "Outlier",
                    "Log P": outlier.get("Log P", ""),
                    "Prefix": outlier.get("prefix", ""),
                    "Suffix": outlier.get("suffix", ""),
                    "Outlier_Reason": outlier.get("outlier_reason", "")
                })

        # DataFrameìœ¼ë¡œ ë³€í™˜ í›„ CSV ìƒì„±
        df = pd.DataFrame(output_data)
        output = io.StringIO()
        df.to_csv(output, index=False, encoding='utf-8')
        output.seek(0)

        # íŒŒì¼ë¡œ ì „ì†¡
        return send_file(
            io.BytesIO(output.getvalue().encode('utf-8')),
            mimetype='text/csv',
            as_attachment=True,
            download_name=f'ganglioside_analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        )

    except Exception as e:
        print(f"Download error: {str(e)}")
        return jsonify({"error": f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500